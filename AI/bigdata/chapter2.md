# chapter 2

## 빅데이터 플랫폼

- 빅데이터 수집부터 저장, 처리, 분석 등 전 과정을 통합적으로 제공  
- 그 기술들을 잘 사용할 수 있도록 준비된 환경

## 빅데이터 플랫폼의 등장 배경

- 비지니스 요구사항 변화
- 데이터 규모와 처리 복잡도 증가
- 데이터 구조의 변화와 신속성 요구
- 데이터 분석 유연성 증대 
  - 다양한 방법론을 통해 텍스트, 음성, 이미지, 동영상 등 요소들의 분석이 가능

## 빅데이터 플랫폼의 구조

- 소프트웨어 계층
  - 데이터 처리 및 분석 엔진
    - 데이터 처리 및 분석
    - 처리 및 분석 워크플로우 구성
    - 데이터 표현
  - 데이터 수집 및 정제 모듈
    - 데이터 추출
    - 데이터 변환
    - 데이터 적재
  - 서비스 관리 모듈
  - 사용자 관리 모듈
    - 인증 및 접속 관리
    - 사용자 서비스 관리
    - SLA 관리
  - 모니터링 모듈
    - 서비스 모니터링
  - 보안 모듈
- 플랫폼 계층
  - 사용자 요청 파싱 모듈
  - 작업 스케쥴링 모듈
  - 데이터 및 자원 할당 모듈
    - 초기 데이터 할당
    - 데이터 재할당 및 복제
    - 초기 지원 할당
    - 지원 재할당 및 스케일링 
  - 프로파일링 모듈
    - 자원 프로파일링 
    - 응용 프로파일링
    - 응용 시뮬
  - 데이터 관리 모듈
  - 자원 관리 모듈
  - 서비스 관리 모듈
  - 사용자 관리 모듈
    - 인증 및 접속 관리
    - 사용자 서비스 관리
    - SLA 관리 
  - 모니터링 모듈
    - 서비스 모니터링
  - 보안 모듈
- 인프라 스트럭처 계층
  - 사용자 요청 파싱 모듈
  - 자원 배치 모듈
    - 초기 자원 배치
    - 자원 재할당 및 스케일링
  - 노드 관리 모듈
  - 스토리지 관리 모듈
  - 네트워크 관리 모듈
  - 서비스 관리 모듈
  - 사용자 관리 모듈
    - 인증 및 접속 관리
    - 사용자 서비스 관리
    - SLA 관리
  - 모니터링 모듈
    - 서비스 모니터링
    - 자원 모니터링
  - 보안 모듈 
- `SLA` : Service Level Agreement
  - 서비스 제공업체와 고객간 맺는 서비스 품질에 대한 계약, 사전에 정의된 수준의 서비스가 제공될 수 있게 품질 보장. 
- 프로파일링
  - 속도 및 최적화에 중점, CPU와 메모리 사용량 및 실행 시간 등을 추적. 

## 빅데이터 처리 기술

### 빅데이터 처리과정과 요소 기술

1. 데이터 생성
   - 내부 데이터
   - 인터넷응로 연결된 외부로부터 생성 된 파일
2. 수집
   - 수집
   - 크롤링, ETL ( 추출, 변환, 적재 )
   - 로그 수집, 센서 네트워크, Open API 등..
3. 저장(공유)
   - 정형, 반정형, 비정형 데이터 포함
   - DBMS or Hadoop, NoSQL 등 다양한 기술
   - 시스템 간의 데이터를 서로 공유 가능
4. 처리
   - 분산 병령, 인메모리(In-Memory) 방식으로 실시간 처리
   - 하둡 or 맵리듀스를 활용
5. 분석
   - 데이터를 신속 정확 분석, 비즈니스에 기여
   - 분야 및 목적에 맞는 분석 기법 선택 중요
   - 통계분석, 데이터 마이닝, 텍스트 마이닝, 기계학습 등... 
6. 시각화
   - 빅데이터 처리 및 분석 결과를 사용자에게 보여주는 기술
   - 해석에 활용
   - 정보 시각화 기술, 시각화 도구, 편집 기술, 실시간 자료 시각화 기술

### 빅데이터 수집

1. 크롤링(Crawling)
2. 로그 수집기
3. 센서 네트워크
4. RSS Reader/Open API
   - 데이터의 생산, 공유, 참여할 수 있는 환경인 웹 2.0을 구현하는 기술 
   - 필요 데이터를 프로그래밍을 통해 수집 가능. 
5. ETL 프로세스 ( Extract, Transform, Load )   
   - 다양한 원천 데이터를 취합해 추출하고 공통된 형식으로 변환하여 적재하는 과정 

### 빅데이터 저장

1. NoSQL( Not-only SQL )
   - 기존의 RDBMS 트랜잭션 속성인 원자성(Atomicity), 일관성(Consistency), 독립성(Isolation), 지속성(Durability)를 유연하게 적용  
   - `Cloudata`, `Hbase`, `Cassandra`, `MongoDB` 등
2. 공유 데이터 시스템 (Shared-data System)
    - 일관성, 가용성(Availability), 분할 내성(Partition Tolerance) 중에서 두개의 속성만 보유 가능 ( CAP 이론 )
    - `CAP이론`
        - **C (Consistency, 일관성)**: 모든 노드가 동시에 같은 데이터를 보는 것
        - **A (Availability, 가용성)**: 시스템이 항상 동작하고 요청에 응답하는 것
        - **P (Partition Tolerance, 분할 내성)**: 네트워크 분할이 발생해도 시스템이 계속 동작
        - **CAP 조합**
            - **CA**: 전통적인 RDBMS (MySQL, PostgreSQL)
            - **CP**: MongoDB, HBase, Redis Cluster
            - **AP**: Cassandra, DynamoDB, CouchDB
        - 분산 시스템에서는 P(분할내성)를 포기할 수 없으므로 실제로는 CP vs AP 선택
3. 병렬 데이터베이스 관리 시스템(Parallel Database Management System)
    - 다수의 마이크로 프로세서를 사용 - 여러 디스크에 질의, 갱신, 입출력 등 데이터베이스 처리를 동시에 수행
    - **VoltDB**
        - 인메모리 OLTP 데이터베이스
        - 초고속 트랜잭션 처리 (백만 TPS 이상)
        - ACID 속성 완전 지원, SQL 호환
    - **SAP HANA**
        - 인메모리 컬럼 지향 데이터베이스
        - OLTP와 OLAP 통합 처리
        - 실시간 분석 및 애플리케이션 플랫폼
    - **Vertica**
        - HP(현 OpenText)의 컬럼 지향 분석 데이터베이스
        - 대용량 데이터 웨어하우스에 최적화
        - 압축률이 높고 빠른 분석 성능
    - **Greenplum**
        - VMware의 대규모 병렬 처리(MPP) 데이터베이스
        - PostgreSQL 기반, 페타바이트급 데이터 처리
        - 오픈소스와 상용 버전 제공
    - **Netezza**
        - IBM의 데이터 웨어하우스 어플라이언스
        - 하드웨어-소프트웨어 통합 솔루션
        - 복잡한 분석 쿼리에 최적화
4. `분산 파일 시스템`
    - 네트워크로 공유하는 여러 호스트의 파일에 접근할 수 있는 파일 시스템
    - 데이터를 분산하여 저장하면 데이터 추출 및 가공 시 빠르게 처리 가능
    - **GFS(Google File System)**
        - Google에서 개발한 분산 파일 시스템
        - 대용량 파일 처리에 최적화 (수 GB ~ TB)
        - 마스터-청크서버 구조, 64MB 청크 단위
        - 3개 복제본으로 내결함성 제공
    - **HDFS(Hadoop Distributed File System)**
        - GFS 기반 오픈소스 구현체
        - 네임노드-데이터노드 구조
        - 기본 128MB 블록 단위, Write-once Read-many 모델
        - Hadoop 생태계의 핵심 구성요소
    - **Amazon S3(Simple Storage Service)**
        - AWS의 클라우드 객체 스토리지 서비스
        - REST API 기반 접근
        - 버킷-객체 구조, 무제한 확장성
        - 99.999999999% 내구성, 다양한 스토리지 클래스 제공 

### 빅데이터 처리 

- 분산 시스템
  - 네트워크상에 분산되어 있는 컴퓨터를 단일 시스템인 것 처름 구동
  - 각 노드는 독립
  - 독립이지만 마치 단일 시스템 처럼
- 병령 시스템 
  - 문제 해결을 위해 CPU등의 자원을 데이터 버스나 지역 통신 시스템 등으로 연결하여 구동
  - 분할 된 작업을 동시에 처리하여 계산 속도를 빠르게 한다
  - 분산 아키텍처, 병렬 처리/고성능 처리, 데이터 파티셔닝을 통한 데이터 병렬성, 데이터복제와 분산
- 분산 병렬 컴퓨팅 
  - 다수의 독립된 컴퓨팅 자원을 네트워크상에 연결하여 이를 제어하는 미들웨어를 이용해 하나의 시스템으로 동작하게 하는 기술 
- 하둡 
  - 분산 처리 환경에서 대용량 데이터 처리 및 분석을 지원하는 오픈소스 소프트웨어 프레임워크 
  - 야후에서 개발 ( 지금은 아파치 소프트웨어 재단 )
  - 하둡 분산파일 시스템인 HDFS와 분산칼럼기반 데이터베이스인 Hbase, 분산 컴퓨팅 지원 프레임워크인 맵리듀스(MapReduce)로 구성
  - 맵리듀스를 통해 실시간 처리 분석 가능 
  - 하둡의 부족한 기능들을 하둡 에코시스템으로 다양한 솔루션 제공
- 아파치 스파크(Apache Spark)
  - In-Memory 방식으로 처리, 하둡보다 처리 속도가 빠름. 
- 맵리듀스(MapReduce)
  - 구글에서 개발한 방대한 데이터 처리를 위한 프로그래밍 모델
  - 효과적인 병렬 및 분산 처리를 지원

### 맵리듀스 

1. input
   - 입력데이터를 읽고 분할
2. Split 
   - 분할 된 데이터를 할당해 맵 작업을 수행, 데이터를 통합 및 재분할
3. Map Phase
   - 통합 및 재분할 된 중간 데이터를 셔플
4. Shuffle and Sort
   - 셔플된 중간 데이터를 이용해 리듀스 작업 수행
5. Reduce Phase
   - 출력 데이터를 생성, 맵리듀스 처리를 종료 

### 빅데이터 분석

- 탐구 요인 분석(EFA: Exploratory Factor Analysis)
  - 데이터 간 상호관계를 파악하여 데이터를 분석
- 확인 요인 분석(CFA: Conbfirmatory Factor Analysis)
  - 관찰된 변수들의 집합 요소 구조를 파악하기 위한 통계쩍 기법을 통해 데이터를 분석 
  
### 데이터 분석 방법

- 분류(Classification)
  - 지도학습 방법 중 하나, 미리 알려진 클래스들로 구분되는 학습 데이터셋(Dataset)을 학습 시켜 새로 추가되는 데이터가 속하는 셋을 찾는 방법
- 군집화(Clustering)
  - 특성이 비슷한 데이터를 하나의 그룹으로 분류
  - 비지도 학습 중 하나 
- 기계 학습(Machine Learning)
  - 인공지는 분야 중 하나, 인간의 학습을 모델링
  - 의사결정트리 등 기호적 학습과 신경망이나 유전 알고리즘 등 비기호적 학습, 베이지안이나 은닉 마코프 등 확률적 학습 등 다양한 기법이 있음. 
- 텍스트 마이닝
  - 비정형 텍스트 데이터에서 유용한 정보와 패턴을 추출하는 기법
  - 자연어 처리 기술을 활용하여 문서 분류, 키워드 추출, 요약 등 수행
- 웹마이닝
  - 웹상의 데이터(웹 페이지, 링크, 로그 등)를 분석하여 유용한 정보를 발견하는 기법
  - 웹 콘텐츠 마이닝, 웹 구조 마이닝, 웹 사용 마이닝으로 구분
- 오피니언 마이닝
  - 텍스트에서 의견, 감정, 평가 등 주관적 정보를 추출하고 분석하는 기법
  - 제품 리뷰, 소셜 미디어 게시물 등에서 긍정/부정 의견 분석
- 리얼리티 마이닝
  - 센서, GPS, 통화 기록 등 실제 행동 데이터를 수집하여 인간 행동 패턴을 분석
  - 모바일 기기와 IoT 센서를 통해 수집된 실시간 데이터 활용
- 소셜 네트워크 분석
  - 사람들 간의 관계와 상호작용을 네트워크 구조로 모델링하여 분석
  - 영향력 있는 노드 발견, 커뮤니티 탐지, 정보 전파 패턴 분석
- 감성 분석
  - 텍스트에서 감정 상태(긍정, 부정, 중립)를 자동으로 판별하는 기법
  - 고객 만족도 조사, 브랜드 모니터링, 여론 분석 등에 활용

## 인공지능

### 기계 학습의 종류 

- **지도 학습(Supervised Learning)**
  - 정답(레이블)이 있는 훈련 데이터로 학습하는 방법
  - 입력과 출력 간의 관계를 학습하여 새로운 데이터의 결과를 예측
  - **분류(Classification)**: 범주형 출력 예측
    - 예제: 이메일 스팸 분류, 이미지 인식, 의료 진단
    - 알고리즘: 의사결정트리, SVM, 랜덤포레스트, 신경망
  - **회귀(Regression)**: 연속적인 수치 예측
    - 예제: 주택 가격 예측, 주식 가격 예측, 매출 예측
    - 알고리즘: 선형회귀, 다항회귀, 신경망

- **비지도 학습(Unsupervised Learning)**
  - 정답(레이블)이 없는 데이터에서 숨겨진 패턴이나 구조를 발견
  - 데이터의 내재된 특성과 관계를 탐색
  - **군집화(Clustering)**: 유사한 특성을 가진 데이터를 그룹화
    - 예제: 고객 세분화, 유전자 분석, 이미지 분할
    - 알고리즘: K-means, 계층적 군집화, DBSCAN
  - **차원 축소(Dimensionality Reduction)**: 데이터의 차원을 줄여 핵심 특성 추출
    - 예제: 데이터 시각화, 노이즈 제거, 특성 선택
    - 알고리즘: PCA, t-SNE, LDA
  - **연관 규칙(Association Rules)**: 데이터 간의 연관성 발견
    - 예제: 장바구니 분석, 추천 시스템
    - 알고리즘: Apriori, FP-Growth

- **준지도 학습(Semi-supervised Learning)**
  - 소량의 레이블된 데이터와 대량의 레이블되지 않은 데이터를 함께 사용
  - 레이블링 비용이 높거나 어려운 상황에서 활용
  - **활용 분야**: 
    - 예제: 웹 페이지 분류, 음성 인식, 의료 영상 분석
    - 텍스트 분류에서 일부 문서만 분류하고 나머지는 미분류 상태
  - **방법**: Self-training, Co-training, Graph-based methods

- **강화 학습(Reinforcement Learning)**
  - 환경과의 상호작용을 통해 보상을 최대화하는 행동을 학습
  - 시행착오를 통해 최적의 정책(Policy)을 찾는 방법
  - **핵심 개념**:
    - 에이전트(Agent): 학습하는 주체
    - 환경(Environment): 에이전트가 상호작용하는 외부 시스템
    - 상태(State): 현재 환경의 상황
    - 행동(Action): 에이전트가 취할 수 있는 행위
    - 보상(Reward): 행동에 대한 피드백
  - **활용 분야**:
    - 예제: 게임 AI(알파고, 체스), 자율주행차, 로봇 제어
    - 추천 시스템, 금융 거래, 자원 할당 최적화
  - **알고리즘**: Q-Learning, Policy Gradient, Actor-Critic

### 인공지능 데이터 학습의 진화

- **전이 학습(Transfer Learning)**
  - 기존의 학습된 모델의 지식을 새로운 문제에 적용하여 학습을 빠르고 효율적으로 수행
  - 주로 이미지, 언어, 텍스트 인식과 같이 지도학습 중 분류모형인 인식 문제에 활용 가능
  - **핵심 개념**: 
    - Fine-tuning: 사전 훈련된 모델을 새로운 데이터셋에 맞게 조정
    - Feature Extraction: 사전 훈련된 모델의 특성 추출기만 사용
  - **활용 예제**:
    - 이미지 분류: ImageNet으로 훈련된 CNN을 의료 영상 분석에 적용
    - 자연어 처리: 일반 텍스트로 훈련된 모델을 법률 문서 분석에 활용
    - 음성 인식: 영어 음성 모델을 한국어 음성 인식에 적용

- **전이학습 기반 사전학습 모형(Pre-trained Model)**
  - 학습 데이터에 의한 인지능력을 갖춘 딥러닝 모형에 추가적인 데이터를 학습시키는 방식
  - **장점**: 적은 데이터로도 높은 성능, 학습 시간 단축, 계산 비용 절약
  - **대표 모델**:
    - **컴퓨터 비전**: ResNet, VGG, EfficientNet
    - **자연어 처리**: BERT, GPT, RoBERTa
    - **음성 처리**: Wav2Vec, DeepSpeech

- **임베딩(Embedding)**
  - 특정 데이터를 숫자로 채워진 벡터, 행렬로 바꾸는 과정
  - 수학적으로 표현된 n차원 벡터들을 통해 컴퓨터가 관계를 유추
  - **종류별 예제**:
    - **Word Embedding**: Word2Vec, GloVe, FastText
      - "왕" - "남자" + "여자" = "여왕" (의미적 관계 표현)
    - **Image Embedding**: CNN의 마지막 층 특성
    - **User Embedding**: 추천 시스템에서 사용자 선호도 벡터화
  - **핵심 특성**:
    - 유사한 의미의 단어들이 벡터 공간에서 가까이 위치
    - 차원 축소를 통한 효율적 표현

### BERT(Bidirectional Encoder Representations from Transformer)

- **기본 정보**:
  - 2018년 구글에서 발표한 언어인식 사전 학습 모형
  - Transformer 구조 기반의 양방향 인코더
- **핵심 특징**:
  - **양방향 학습**: 문맥의 앞뒤를 모두 고려하여 단어 이해
  - **Masked Language Model**: 일부 단어를 마스킹하고 예측하는 방식으로 학습
  - **Next Sentence Prediction**: 두 문장의 연관성 학습
- **활용 분야**:
  - 질의응답 시스템, 감정 분석, 문서 분류, 기계 번역
  - 검색 엔진, 챗봇, 문서 요약

### 빅데이터와 인공지능의 관계

- **인공지능을 위한 학습 데이터 확보**
  - 양질의 데이터 확보는 결국 성공적인 인공지능 구현과 직결
  - **딥러닝의 데이터 요구사항**:
    - 깊은 구조를 통해 무한한 모수 추정이 필요 → 많은 양의 데이터 필요
    - 일반적으로 수만~수백만 개의 학습 데이터 필요
  - **데이터 품질 요소**:
    - 정확성, 완전성, 일관성, 적시성, 관련성

- **데이터 전처리와 애노테이션**
  - **데이터 가공의 필요성**: 원시 데이터를 학습 가능한 형태로 변환
  - **애노테이션(Annotation) 작업**:
    - 데이터상의 주석 작업, 알고리즘이 무엇을 학습해야 하는지 알려주는 작업
    - **예제**:
      - 이미지 분류: 고양이/개 라벨링
      - 객체 탐지: 이미지 내 물체 위치 표시
      - 감정 분석: 텍스트에 긍정/부정 라벨 부착
      - 의료 진단: X-ray 이미지에 질병 유무 표시

- **빅데이터 기술의 AI 기여도**:
  - **데이터 수집**: 웹 크롤링, IoT 센서, 로그 수집
  - **데이터 저장**: 분산 파일 시스템(HDFS), NoSQL 데이터베이스
  - **데이터 처리**: MapReduce, Spark를 통한 대용량 데이터 전처리
  - **실시간 처리**: 스트리밍 데이터를 실시간으로 AI 모델에 공급  

### 인공지능 기술 동향

- **기계학습 프레임워크(Machine Learning Framework)**
  - 기계학습 모델을 개발하고 배포하기 위한 소프트웨어 라이브러리 및 도구 모음
  - 데이터 전처리부터 모델 훈련, 평가, 배포까지 전 과정을 지원
  - **주요 프레임워크**:
    - **TensorFlow**: Google 개발, 딥러닝에 특화, 분산 처리 지원
    - **PyTorch**: Facebook 개발, 동적 그래프, 연구용에 적합
    - **Scikit-learn**: 전통적 기계학습 알고리즘, 간단한 인터페이스
    - **Keras**: 고수준 API, TensorFlow 위에서 동작
  - **활용 예제**: 이미지 분류, 자연어 처리, 추천 시스템, 시계열 예측

- **생성적 적대 신경망(GAN: Generative Adversarial Network)**
  - 생성자(Generator)와 판별자(Discriminator) 두 신경망이 경쟁하며 학습하는 구조
  - 생성자는 가짜 데이터를 생성하고, 판별자는 진짜와 가짜를 구별
  - **핵심 특징**:
    - 비지도 학습 방식으로 새로운 데이터 생성
    - Min-Max 게임 이론 기반의 적대적 학습
    - 실제와 구별하기 어려운 고품질 합성 데이터 생성 가능
  - **활용 예제**:
    - **이미지 생성**: 얼굴 이미지, 예술 작품, 패션 디자인
    - **데이터 증강**: 부족한 훈련 데이터 보완
    - **스타일 변환**: 사진을 그림 스타일로 변환
    - **음성 합성**: 자연스러운 음성 생성
  - **대표 모델**: DCGAN, StyleGAN, CycleGAN, Pix2Pix

- **오토인코더(Auto-encoder)**
  - 입력 데이터를 압축(인코딩)한 후 복원(디코딩)하는 비지도 학습 신경망
  - 인코더와 디코더로 구성되며, 입력과 출력이 동일하도록 학습
  - **핵심 개념**:
    - **인코더**: 입력 데이터를 저차원 잠재 공간으로 압축
    - **디코더**: 압축된 표현을 원본 데이터로 복원
    - **잠재 공간(Latent Space)**: 압축된 특성 표현
  - **활용 예제**:
    - **차원 축소**: 고차원 데이터의 핵심 특성 추출
    - **이상 탐지**: 정상 패턴과 다른 데이터 발견
    - **노이즈 제거**: 손상된 이미지나 신호 복원  
    - **데이터 압축**: 효율적인 데이터 저장
  - **변형 모델**: Variational Autoencoder(VAE), Sparse Autoencoder

- **설명가능한 인공지능(XAI: eXplainable AI)**
  - AI 모델의 의사결정 과정을 인간이 이해할 수 있도록 설명하는 기술
  - 블랙박스 모델의 투명성과 신뢰성을 높이는 것이 목표
  - **필요성**:
    - 의료, 금융, 법률 등 고위험 분야에서 의사결정 근거 필요
    - AI 윤리와 공정성 확보
    - 규제 준수 및 책임 소재 명확화
  - **주요 기법**:
    - **LIME**: 개별 예측에 대한 지역적 설명
    - **SHAP**: 게임 이론 기반 특성 중요도 계산
    - **Grad-CAM**: CNN에서 중요한 영역 시각화
    - **Feature Importance**: 특성별 기여도 분석
  - **활용 예제**:
    - **의료 진단**: X-ray에서 병변 부위 하이라이트
    - **금융**: 대출 승인/거부 이유 설명
    - **자율주행**: 브레이크 판단 근거 제시
    - **추천 시스템**: 추천 이유 설명

- **기계학습 자동화(AutoML: Automated Machine Learning)**
  - 기계학습 파이프라인의 전 과정을 자동화하는 기술
  - 전문 지식 없이도 고성능 모델을 개발할 수 있도록 지원
  - **자동화 영역**:
    - **데이터 전처리**: 결측치 처리, 특성 선택, 정규화
    - **모델 선택**: 최적 알고리즘 자동 선택
    - **하이퍼파라미터 튜닝**: 최적 매개변수 탐색
    - **특성 엔지니어링**: 새로운 특성 자동 생성
  - **핵심 기술**:
    - **Neural Architecture Search(NAS)**: 최적 신경망 구조 탐색
    - **Bayesian Optimization**: 효율적인 하이퍼파라미터 최적화
    - **Meta-Learning**: 과거 경험을 활용한 빠른 학습
  - **활용 예제**:
    - **비즈니스**: 매출 예측, 고객 이탈 예측
    - **의료**: 질병 진단 모델 자동 구축
    - **제조**: 품질 관리, 예측 정비
  - **대표 플랫폼**: Google AutoML, H2O.ai, Auto-sklearn, TPOT

### 기술 동향의 의미

- **민주화**: AutoML로 인한 AI 기술 접근성 향상
- **신뢰성**: XAI를 통한 AI 결과에 대한 신뢰도 증가  
- **창조성**: GAN을 통한 새로운 콘텐츠 생성 능력
- **효율성**: 오토인코더를 통한 데이터 압축 및 특성 학습
- **표준화**: 프레임워크를 통한 개발 과정 표준화

## 개인정보의 정의 

- 살아 있는 개인에 관한 정보, 개인을 알아볼 수 있는 정보 
